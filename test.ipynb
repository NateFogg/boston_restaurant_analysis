{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from config import TOKEN\n",
    "    \n",
    "businesses = pd.DataFrame()\n",
    "final_json_data = []\n",
    "ZIPS = {'East Boston':['02128'], 'Charlestown': ['02129'], 'Allston': ['02163','02134'], 'Brighton':['02135'], 'Beacon Hill': ['02108'], \n",
    "        'Back Bay': ['02116', '02199'],'Chinatown': ['02111'], 'Dorchester': ['02121', '02122', '02124', '02125'], 'Fenway': ['02115', '02215'],\n",
    "          'Hyde Park': ['02136'], 'Jamaica Plain': ['02130'], 'Mattapan': ['02126'], 'Mission Hill': ['02120'],'North End': ['02113', '02109'], 'Roslindale': ['02131'], \n",
    "          'Roxbury': ['02119'], 'South Boston': ['02127', '02210'], 'South End': ['02118'], 'West End': ['02114'], 'West Roxbury': ['02132'], 'Wharf District': ['02110'],\n",
    "           'Downtown': ['02203', '02201']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = 0\n",
    "for neighborhood, zip_codes in ZIPS.items():\n",
    "    for code in zip_codes:\n",
    "\n",
    "        offset = 0\n",
    "        add_count = 1\n",
    "\n",
    "        while add_count > 0 and offset < 1000:\n",
    "            add_count = 0\n",
    "            # grab data from the api\n",
    "            url = 'https://api.yelp.com/v3/businesses/search?location=Boston%2C%20MA%2C%' + code + '&term=restaurants&sort_by=distance&limit=50&offset=' + str(offset)\n",
    "            headers = {\n",
    "                        'accept': 'application/json',\n",
    "                        'Authorization': 'Bearer ' + TOKEN\n",
    "                    }\n",
    "\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            # Handle the API request error here\n",
    "            if response.status_code == 200:\n",
    "                json_data = response.json()\n",
    "            else:\n",
    "                print('Failed to retrieve data from the API.')\n",
    "                json_data = None\n",
    "\n",
    "            # if businesses - location - zip_code not in the list of neighborhood do not add\n",
    "            # may need to use a loop to drop the index within json data\n",
    "            business_list = json_data['businesses']\n",
    "            for bus in business_list:\n",
    "                if bus['location']['zip_code'] == code:\n",
    "                    bus['neighborhood'] = neighborhood\n",
    "                    final_json_data.append(bus)\n",
    "                    add_count += 1\n",
    "\n",
    "\n",
    "            # increase the offset\n",
    "            offset += 50\n",
    "            if offset > 950:\n",
    "                print('EXCEEDED OFFSET LIMIT!')\n",
    "\n",
    "            # do not call from the api too fast\n",
    "            time.sleep(1)\n",
    "            calls += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_json_data:\n",
    "    for dict in final_json_data:\n",
    "        # flatten the data\n",
    "        bus_row = pd.json_normalize(dict) \n",
    "        \n",
    "        # append the new row to data frame\n",
    "        businesses = pd.concat([businesses, bus_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not businesses.empty:\n",
    "    # yelp likes to return duplicates \n",
    "    businesses = businesses.drop_duplicates(subset = ['id'])\n",
    "\n",
    "    # make a new row for each dictionary in the categories col\n",
    "    bus_exploded = businesses.explode('categories').reset_index(drop=True)\n",
    "\n",
    "    # encode all the information into new binary categorical columns \n",
    "    bus_encoded = pd.get_dummies(bus_exploded['categories'].apply(pd.Series))\n",
    "\n",
    "    # concat the new columns to the exploded dataframe so that the rows match\n",
    "    bus_final = pd.concat([bus_exploded, bus_encoded], axis=1)\n",
    "\n",
    "    # change all column names to string\n",
    "    bus_final.columns = bus_final.columns.map(str)\n",
    "\n",
    "    # drop the titles\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('title')]\n",
    "\n",
    "    # need to make the rows unique and get the sum of alias cols by partitioning by business id \n",
    "    grouped = bus_final.groupby('id')\n",
    "\n",
    "    # Use 'transform' to calculate the sum of 'value1' and 'value2' within each group\n",
    "    for col in bus_final.columns[25:]:\n",
    "        bus_final[col[6:]] = grouped[col].transform('sum')\n",
    "    bus_final = bus_final.drop_duplicates(subset = ['id'])\n",
    "\n",
    "\n",
    "\n",
    "    # make a new row for each dictionary in the transaction col\n",
    "    bus_exploded = bus_final.explode('transactions').reset_index(drop=True)\n",
    "\n",
    "    # encode all the information into new binary categorical columns \n",
    "    bus_encoded = pd.get_dummies(bus_exploded['transactions'].apply(pd.Series))\n",
    "\n",
    "    # concat the new columns to the exploded dataframe so that the rows match\n",
    "    bus_final = pd.concat([bus_exploded, bus_encoded], axis=1)\n",
    "\n",
    "    grouped = bus_final.groupby('id')\n",
    "\n",
    "    # Use 'transform' to calculate the sum of 'value1' and 'value2' within each group\n",
    "    for col in bus_final.columns[-3:]:\n",
    "        bus_final[col[2:]] = grouped[col].transform('sum')\n",
    "    bus_final = bus_final.drop_duplicates(subset = ['id'])\n",
    "\n",
    "\n",
    "    # clean up\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('alias')]\n",
    "    bus_final = bus_final.drop(columns=['categories', 'location.state', 'location.country', 'location.display_address'])\n",
    "    bus_final = bus_final.drop(columns=['transactions'])\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('0_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bus_final.empty:\n",
    "    bus_copy = bus_final\n",
    "    # feature engineering\n",
    "\n",
    "    # encode the ratings \n",
    "    bus_copy = pd.concat([bus_copy, pd.get_dummies(bus_copy['rating'])], axis=1)\n",
    "    # encode the neighborhoods\n",
    "    bus_copy = pd.concat([bus_copy, pd.get_dummies(bus_copy['neighborhood'])], axis=1)\n",
    "    # encode the price options to different cols\n",
    "    bus_copy = pd.concat([bus_copy, pd.get_dummies(bus_copy['price'])], axis=1)\n",
    "\n",
    "    bus_copy.columns = bus_copy.columns.map(str)\n",
    "    \n",
    "    # change all empty values to nan\n",
    "    bus_copy = bus_copy.replace('', np.nan)\n",
    "\n",
    "    # has image from image_url\n",
    "    bus_copy['has_image'] = np.where(bus_copy['image_url'].isna(), 0, 1)\n",
    "\n",
    "    # has_phone from phone\n",
    "    bus_copy['has_phone'] = np.where(bus_copy['phone'].isna(), 0, 1) \n",
    "\n",
    "    # has_st_add from location.address1\n",
    "    bus_copy['has_st_add'] = np.where(bus_copy['location.address1'].isna(), 0, 1) \n",
    "\n",
    "    # has_price from price\n",
    "    bus_copy['has_price'] = np.where(bus_copy['price'].isna(), 0, 1) \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate a Balanced Rating Score (BRS)\n",
    "    weight_average_rating = 0.7\n",
    "    weight_review_count = 0.3\n",
    "\n",
    "    # Normalize Average Rating\n",
    "    bus_copy['norm_rating'] = bus_copy['rating'] / 5\n",
    "\n",
    "    # Normalize Review Count using logarithm and min-max scaling\n",
    "    bus_copy['norm_count'] = np.log10(bus_copy['review_count'] + 0.000000001)\n",
    "    bus_copy['norm_count'] = (bus_copy['norm_count'] - bus_copy['norm_count'].min()) / (bus_copy['norm_count'].max() - bus_copy['norm_count'].min())\n",
    "\n",
    "    bus_copy['brs'] = (weight_average_rating * bus_copy['norm_rating']) + (weight_review_count * bus_copy['norm_count'])\n",
    "\n",
    "    # cols to drop and rename\n",
    "    bus_copy = bus_copy.drop(columns=['0', '', 'image_url', 'is_closed', 'url', 'norm_count', 'norm_rating', 'price', 'phone', 'display_phone', 'location.address1', 'location.address2', 'location.address3'])\n",
    "    bus_copy = bus_copy.rename(columns={'coordinates.latitude': 'latitude', 'coordinates.longitude': 'longitude', 'location.city': 'city', 'location.zip_code': 'zip_code'})\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "# after all of this is done check all columns for nan or None vlaues or other not allowed values\n",
    "# verify the location is within Boston\n",
    "# see distances\n",
    "# add a neighborhood column\n",
    "# check that zipcode belongs to boston\n",
    "# exclude 02467 as it is chestnut hill and this would interfere with the brighton search, this leaves out two restaurants technically in boston\n",
    "# exclude 02151 beachmont\n",
    "\n",
    "    na_values = (bus_copy.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "'''\n",
    "- \n",
    "- \n",
    "- Visualize the sampling per neighborhood\n",
    "- Distribution of the restaurant tags\n",
    "- Distribution of the has images, phone, and address\n",
    "- Distribution of the prices\n",
    "- Histogram of the calculated score\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Distribution of review count\n",
    "plt.hist(bus_copy['review_count'], color='blue', edgecolor='black')\n",
    "plt.xlabel('Review Count')\n",
    "plt.ylabel('No. of Restaurants')\n",
    "plt.title('Log Distribution of Review Counts')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of rating\n",
    "rating_counts = bus_copy.loc[:, '0.0':'5.0'].sum()\n",
    "rating_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Rating Counts')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "# Count of each neighborhood\n",
    "neighborhood_counts = bus_copy.loc[:, 'Allston':'West Roxbury'].sum()\n",
    "neighborhood_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Neighborhood Counts')\n",
    "plt.xlabel('Neighborhoods')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "%matplotlib inline\n",
    "\n",
    "bos_map = gpd.read_file('City_of_Boston_Boundary/City_of_Boston_Boundary.shp')\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(bus_copy['longitude'], bus_copy['latitude'])]\n",
    "crs = {'init':'epsg:4326'}\n",
    "\n",
    "geo_df = gpd.GeoDataFrame(bus_copy, # specify our data\n",
    "                          crs=crs, # specify our coordinate reference system\n",
    "                          geometry=geometry) # specify the geometry list we created\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "bos_map.plot(ax=ax, alpha=0.4, color='grey')\n",
    "\n",
    "for neighborhood in bus_copy.columns[202:222]:\n",
    "    geo_df[geo_df[neighborhood] == 1].plot(ax=ax,\n",
    "                                            markersize=2, \n",
    "                                            color='blue', \n",
    "                                            marker='o', \n",
    "                                            label=neighborhood)\n",
    "\n",
    "\n",
    "plt.legend(prop={'size':15})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
