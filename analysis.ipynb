{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import TOKEN\n",
    "\n",
    "if final_json_data:\n",
    "    for dict in final_json_data:\n",
    "        # flatten the data\n",
    "        bus_row = pd.json_normalize(dict) \n",
    "        \n",
    "        # append the new row to data frame\n",
    "        businesses = pd.concat([businesses, bus_row])\n",
    "if not businesses.empty:\n",
    "    # yelp likes to return duplicates \n",
    "    businesses = businesses.drop_duplicates(subset = ['id'])\n",
    "\n",
    "    # make a new row for each dictionary in the categories col\n",
    "    bus_exploded = businesses.explode('categories').reset_index(drop=True)\n",
    "\n",
    "    # encode all the information into new binary categorical columns \n",
    "    bus_encoded = pd.get_dummies(bus_exploded['categories'].apply(pd.Series))\n",
    "\n",
    "    # concat the new columns to the exploded dataframe so that the rows match\n",
    "    bus_final = pd.concat([bus_exploded, bus_encoded], axis=1)\n",
    "\n",
    "    # change all column names to string\n",
    "    bus_final.columns = bus_final.columns.map(str)\n",
    "\n",
    "    # drop the titles\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('title')]\n",
    "\n",
    "    # need to make the rows unique and get the sum of alias cols by partitioning by business id \n",
    "    grouped = bus_final.groupby('id')\n",
    "\n",
    "    # Use 'transform' to calculate the sum of 'value1' and 'value2' within each group\n",
    "    for col in bus_final.columns[25:]:\n",
    "        bus_final[col[6:]] = grouped[col].transform('sum')\n",
    "    bus_final = bus_final.drop_duplicates(subset = ['id'])\n",
    "\n",
    "    # make a new row for each dictionary in the transaction col\n",
    "    bus_exploded = bus_final.explode('transactions').reset_index(drop=True)\n",
    "\n",
    "    # encode all the information into new binary categorical columns \n",
    "    bus_encoded = pd.get_dummies(bus_exploded['transactions'].apply(pd.Series))\n",
    "\n",
    "    # concat the new columns to the exploded dataframe so that the rows match\n",
    "    bus_final = pd.concat([bus_exploded, bus_encoded], axis=1)\n",
    "\n",
    "    grouped = bus_final.groupby('id')\n",
    "\n",
    "    # Use 'transform' to calculate the sum of 'value1' and 'value2' within each group\n",
    "    for col in bus_final.columns[-3:]:\n",
    "        bus_final[col[2:]] = grouped[col].transform('sum')\n",
    "    bus_final = bus_final.drop_duplicates(subset = ['id'])\n",
    "\n",
    "\n",
    "    # clean up\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('alias')]\n",
    "    bus_final = bus_final.drop(columns=['categories', 'location.state', 'location.country', 'location.display_address'])\n",
    "    bus_final = bus_final.drop(columns=['transactions'])\n",
    "    bus_final = bus_final.loc[:,~bus_final.columns.str.startswith('0_')]\n",
    "\n",
    "    # feature engineering\n",
    "\n",
    "    # encode the neighborhoods\n",
    "    bus_final = pd.concat([bus_final, pd.get_dummies(bus_final['neighborhood'])], axis=1)\n",
    "\n",
    "    bus_final.columns = bus_final.columns.map(str)\n",
    "\n",
    "    # change all empty values to nan\n",
    "    bus_final = bus_final.replace('', np.nan)\n",
    "\n",
    "    # encode the price options to scale\n",
    "    bus_final['price'].replace({'$':1, '$$':2, '$$$':3, '$$$$':4}, inplace=True)\n",
    "    bus_final['price'].fillna(0, inplace=True)\n",
    "\n",
    "    # has image from image_url\n",
    "    bus_final['has_image'] = np.where(bus_final['image_url'].isna(), 0, 1)\n",
    "\n",
    "    # has_phone from phone\n",
    "    bus_final['has_phone'] = np.where(bus_final['phone'].isna(), 0, 1) \n",
    "\n",
    "    # has_st_add from location.address1\n",
    "    bus_final['has_st_add'] = np.where(bus_final['location.address1'].isna(), 0, 1) \n",
    "    \n",
    "    # need to remove the businesses that have a review count of zero as these businesses will impact our analysis of what makes a good restaurant\n",
    "    bus_final = bus_final[bus_final['review_count'] > 0]\n",
    "\n",
    "    # Calculate a Balanced Rating Score (BRS)\n",
    "    weight_average_rating = 0.7\n",
    "    weight_review_count = 0.3\n",
    "\n",
    "    # Normalize Average Rating\n",
    "    bus_final['norm_rating'] = bus_final['rating'] / 5\n",
    "\n",
    "    # Normalize Review Count using logarithm and min-max scaling\n",
    "    bus_final['norm_count'] = np.log10(bus_final['review_count'] + 0.000000001)\n",
    "    bus_final['norm_count'] = (bus_final['norm_count'] - bus_final['norm_count'].min()) / (bus_final['norm_count'].max() - bus_final['norm_count'].min())\n",
    "\n",
    "    bus_final['brs'] = (weight_average_rating * bus_final['norm_rating']) + (weight_review_count * bus_final['norm_count'])\n",
    "\n",
    "\n",
    "    # cols to drop and rename\n",
    "    bus_final = bus_final.drop(columns=['image_url', 'is_closed', 'url', 'norm_count', 'norm_rating', 'phone', 'display_phone', 'location.address1', 'location.address2', 'location.address3'])\n",
    "    bus_final = bus_final.rename(columns={'coordinates.latitude': 'latitude', 'coordinates.longitude': 'longitude', 'location.city': 'city', 'location.zip_code': 'zip_code'})\n",
    "    \n",
    "    # check the integrity of the data\n",
    "    na_values = (bus_final.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geoplot\n",
    "import geoplot.crs as gcrs\n",
    "from shapely.geometry import Point\n",
    "\n",
    "bos_map = gpd.read_file('Boston_Neighborhoods/Boston_Neighborhoods.shp')\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(bus_final['longitude'], bus_final['latitude'])]\n",
    "crs = {'init':'epsg:4326'}\n",
    "\n",
    "geo_df = gpd.GeoDataFrame(bus_final, # specify our data\n",
    "                          crs=crs, # specify our coordinate reference system\n",
    "                          geometry=geometry) # specify the geometry list we created\n",
    "ax = geoplot.polyplot(bos_map, projection=gcrs.AlbersEqualArea(), zorder=2, figsize=(15, 15))\n",
    "geoplot.kdeplot(geo_df, cmap='Reds', thresh=0, fill=True, clip=bos_map, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.explore(\n",
    "    column=\"neighborhood\",  \n",
    "    tooltip=[\"name\", 'neighborhood', 'id', 'distance', 'zip_code'],\n",
    "    popup=True,  # show all values in popup (on click)\n",
    "    tiles=\"CartoDB positron\",  # use \"CartoDB positron\" tiles\n",
    "    cmap=\"Set1\",  # use \"Set1\" matplotlib colormap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "'''\n",
    "- \n",
    "- \n",
    "- Visualize the sampling per neighborhood\n",
    "- Distribution of the restaurant tags\n",
    "- Distribution of the has images, phone, and address\n",
    "- Distribution of the prices\n",
    "- Histogram of the calculated score\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Will need to make these graphs more presentable\n",
    "\n",
    "# Distribution of balanced rating score\n",
    "plt.hist(bus_final['brs'], color='blue', edgecolor='black')\n",
    "plt.axvline(bus_final['brs'].median(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.xlabel('BRS')\n",
    "plt.ylabel('No. of Restaurants')\n",
    "plt.title('Distribution of BRS')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of review count\n",
    "plt.hist(bus_final['review_count'], color='blue', edgecolor='black')\n",
    "plt.axvline(bus_final['review_count'].median(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.xlabel('Review Count')\n",
    "plt.ylabel('No. of Restaurants')\n",
    "plt.title('Log Distribution of Review Counts')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of rating\n",
    "rating_counts = bus_final.groupby(['rating'])['rating'].count()\n",
    "rating_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Rating Counts')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()\n",
    "\n",
    "# Count of each neighborhood\n",
    "neighborhood_counts = bus_final.loc[:, 'Allston':'West Roxbury'].sum()\n",
    "neighborhood_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Neighborhood Counts')\n",
    "plt.xlabel('Neighborhoods')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.show()\n",
    "\n",
    "# Counts of prices\n",
    "price_counts = bus_final.groupby(['price'])['price'].count()\n",
    "price_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Price Counts')\n",
    "plt.xlabel('Prices')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Counts of tags\n",
    "tag_counts = bus_final.loc[:, ['delivery', 'pickup', 'restaurant_reservation', 'has_image', 'has_phone', 'has_st_add']].sum()\n",
    "\n",
    "tag_counts.plot(kind='bar', color='skyblue')\n",
    "plt.axhline(y = bus_final.shape[0], color = 'r', linestyle = '-')\n",
    "plt.title('Tag Counts')\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=50)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "# cuisine occurence\n",
    "cuisine_counts = (bus_final.loc[:, 'acaibowls':'wraps'].sum().to_frame()).sort_values([0], ascending = False)\n",
    "\n",
    "cuisine_counts[:30].plot(kind='bar', color='skyblue')\n",
    "plt.title('Cuisine Counts')\n",
    "plt.xlabel('Cuisines')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# median brs of neighborhoods\n",
    "bus_final.groupby([\"neighborhood\"])[\"brs\"].median().to_frame().plot(kind='bar', color='skyblue')\n",
    "plt.axhline(y = bus_final['brs'].median(), color = 'r', linestyle = '-')\n",
    "plt.title('Median BRS By Neighborhood')\n",
    "plt.xlabel('Neighborhood')\n",
    "plt.ylabel('Median')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "# median brs of price\n",
    "bus_final.groupby([\"price\"])[\"brs\"].median().to_frame().plot(kind='bar', color='skyblue')\n",
    "plt.axhline(y = bus_final['brs'].median(), color = 'r', linestyle = '-')\n",
    "plt.title('Median BRS By Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Median')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "column_names = bus_final.columns.tolist()\n",
    "\n",
    "# Splitting data into X (features) and y (target)\n",
    "y = bus_final['brs']\n",
    "X = bus_final.drop(['id', 'name', 'review_count', 'rating', 'distance', 'neighborhood', 'latitude', 'longitude', 'city', 'zip_code','brs'], axis=1)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "regr = DecisionTreeRegressor(min_samples_split=25, max_depth=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean squared error and r2\n",
    "print(f\"Mean Squared Error: {(mean_squared_error(y_test, y_pred))}\")\n",
    "print('R Squared Score is:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "text_representation = tree.export_text(regr)\n",
    "plt.scatter(y_test, y_pred, c='blue')\n",
    "feature_importances = regr.feature_importances_\n",
    "feature_importances = pd.DataFrame(regr.feature_importances_, index=X_train.columns, columns=[\"Importance\"])\n",
    "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(regr, \n",
    "                   feature_names=regr.feature_names_in_,  \n",
    "                   class_names='brs',\n",
    "                   filled=True)\n",
    "fig.savefig(\"decistion_tree.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtreeviz \n",
    "\n",
    "viz_model = dtreeviz.model(regr,\n",
    "                           X_train, y_train,\n",
    "                           feature_names=regr.feature_names_in_,\n",
    "                           target_name='brs')\n",
    "viz_model.view(scale=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at out most important features\n",
    "\n",
    "plt.figure()\n",
    "custom_labels = ['No Price', '\\$', '\\$\\$', '\\$\\$\\$', '\\$\\$\\$\\$']\n",
    "sns.boxplot(x = X['price'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "plt.xlabel('')\n",
    "plt.show()\n",
    "\n",
    "# Label for others are yes and no\n",
    "custom_labels = ['No', 'Yes']\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['has_image'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['hotdogs'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['pizza'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['delivery'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['chicken_wings'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Dorchester'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['East Boston'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Mattapan'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['chinese'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['West End'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Fenway'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['waffles'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['has_phone'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['kosher'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['South Boston'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['mediterranean'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "           \n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Roxbury'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Beacon Hill'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Roslindale'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['cocktailbars'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x = X['Wharf District'],\n",
    "            y = y)\n",
    "plt.xticks(range(len(custom_labels)), custom_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only important features for random forest regression\n",
    "X = X[feature_importances.index[:22].tolist()]\n",
    "\n",
    "# Run a random forest, gradient boost, and xgboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "regr = RandomForestRegressor(min_samples_split=25, max_depth=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
